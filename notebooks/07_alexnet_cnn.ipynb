{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper 7: ImageNet Classification with Deep Convolutional Neural Networks\n",
    "## Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton (2012)\n",
    "\n",
    "### AlexNet: The CNN that Started the Deep Learning Revolution\n",
    "\n",
    "AlexNet won ImageNet 2012 with a top-5 error of 15.3%, crushing the competition (26.2%). This paper reignited interest in deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import correlate2d\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer Implementation\n",
    "\n",
    "The core building block of CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def conv2d(input_image, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    2D Convolution operation\n",
    "    \n",
    "    input_image: (H, W) or (C, H, W)\n",
    "    kernel: (out_channels, in_channels, kH, kW)\n",
    "    \"\"\"\n",
    "    if len(input_image.shape) == 2:\n",
    "        input_image = input_image[np.newaxis, :, :]\n",
    "    \n",
    "    in_channels, H, W = input_image.shape\n",
    "    out_channels, _, kH, kW = kernel.shape\n",
    "    \n",
    "    # Add padding\n",
    "    if padding > 0:\n",
    "        input_padded = np.pad(input_image, \n",
    "                             ((0, 0), (padding, padding), (padding, padding)), \n",
    "                             mode='constant')\n",
    "    else:\n",
    "        input_padded = input_image\n",
    "    \n",
    "    # Output dimensions\n",
    "    out_H = (H + 2*padding - kH) // stride + 1\n",
    "    out_W = (W + 2*padding - kW) // stride + 1\n",
    "    \n",
    "    output = np.zeros((out_channels, out_H, out_W))\n",
    "    \n",
    "    # Perform convolution\n",
    "    for oc in range(out_channels):\n",
    "        for i in range(out_H):\n",
    "            for j in range(out_W):\n",
    "                h_start = i * stride\n",
    "                w_start = j * stride\n",
    "                \n",
    "                # Extract patch\n",
    "                patch = input_padded[:, h_start:h_start+kH, w_start:w_start+kW]\n",
    "                \n",
    "                # Convolve with kernel\n",
    "                output[oc, i, j] = np.sum(patch * kernel[oc])\n",
    "    \n",
    "    return output\n",
    "\n",
    "def max_pool2d(input_image, pool_size=2, stride=2):\n",
    "    \"\"\"\n",
    "    Max pooling operation\n",
    "    \"\"\"\n",
    "    C, H, W = input_image.shape\n",
    "    \n",
    "    out_H = (H - pool_size) // stride + 1\n",
    "    out_W = (W - pool_size) // stride + 1\n",
    "    \n",
    "    output = np.zeros((C, out_H, out_W))\n",
    "    \n",
    "    for c in range(C):\n",
    "        for i in range(out_H):\n",
    "            for j in range(out_W):\n",
    "                h_start = i * stride\n",
    "                w_start = j * stride\n",
    "                \n",
    "                pool_region = input_image[c, h_start:h_start+pool_size, \n",
    "                                         w_start:w_start+pool_size]\n",
    "                output[c, i, j] = np.max(pool_region)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Test convolution\n",
    "test_image = np.random.randn(1, 8, 8)\n",
    "test_kernel = np.random.randn(3, 1, 3, 3) * 0.1\n",
    "\n",
    "conv_output = conv2d(test_image, test_kernel, stride=1, padding=1)\n",
    "print(f\"Input shape: {test_image.shape}\")\n",
    "print(f\"Kernel shape: {test_kernel.shape}\")\n",
    "print(f\"Conv output shape: {conv_output.shape}\")\n",
    "\n",
    "pooled = max_pool2d(conv_output, pool_size=2, stride=2)\n",
    "print(f\"After max pooling: {pooled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet Architecture (Simplified)\n",
    "\n",
    "Original: 227x227x3 → 5 conv layers → 3 FC layers → 1000 classes\n",
    "\n",
    "Our simplified version for 32x32 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetSimplified:\n",
    "    def __init__(self, num_classes=10):\n",
    "        \"\"\"\n",
    "        Simplified AlexNet for 32x32 images (like CIFAR-10)\n",
    "        \n",
    "        Architecture:\n",
    "        - Conv1: 3x3x3 -> 32 filters\n",
    "        - MaxPool\n",
    "        - Conv2: 32 -> 64 filters\n",
    "        - MaxPool\n",
    "        - Conv3: 64 -> 128 filters\n",
    "        - FC layers\n",
    "        \"\"\"\n",
    "        # Conv layers\n",
    "        self.conv1_filters = np.random.randn(32, 3, 3, 3) * 0.01\n",
    "        self.conv1_bias = np.zeros(32)\n",
    "        \n",
    "        self.conv2_filters = np.random.randn(64, 32, 3, 3) * 0.01\n",
    "        self.conv2_bias = np.zeros(64)\n",
    "        \n",
    "        self.conv3_filters = np.random.randn(128, 64, 3, 3) * 0.01\n",
    "        self.conv3_bias = np.zeros(128)\n",
    "        \n",
    "        # FC layers (after conv: 128 * 4 * 4 = 2048)\n",
    "        self.fc1_weights = np.random.randn(2048, 512) * 0.01\n",
    "        self.fc1_bias = np.zeros(512)\n",
    "        \n",
    "        self.fc2_weights = np.random.randn(512, num_classes) * 0.01\n",
    "        self.fc2_bias = np.zeros(num_classes)\n",
    "    \n",
    "    def forward(self, x, use_dropout=False, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        x: (3, 32, 32) image\n",
    "        \"\"\"\n",
    "        # Conv1 + ReLU + MaxPool\n",
    "        conv1 = conv2d(x, self.conv1_filters, stride=1, padding=1)\n",
    "        conv1 += self.conv1_bias[:, np.newaxis, np.newaxis]\n",
    "        conv1 = relu(conv1)\n",
    "        pool1 = max_pool2d(conv1, pool_size=2, stride=2)  # 32 x 16 x 16\n",
    "        \n",
    "        # Conv2 + ReLU + MaxPool\n",
    "        conv2 = conv2d(pool1, self.conv2_filters, stride=1, padding=1)\n",
    "        conv2 += self.conv2_bias[:, np.newaxis, np.newaxis]\n",
    "        conv2 = relu(conv2)\n",
    "        pool2 = max_pool2d(conv2, pool_size=2, stride=2)  # 64 x 8 x 8\n",
    "        \n",
    "        # Conv3 + ReLU + MaxPool\n",
    "        conv3 = conv2d(pool2, self.conv3_filters, stride=1, padding=1)\n",
    "        conv3 += self.conv3_bias[:, np.newaxis, np.newaxis]\n",
    "        conv3 = relu(conv3)\n",
    "        pool3 = max_pool2d(conv3, pool_size=2, stride=2)  # 128 x 4 x 4\n",
    "        \n",
    "        # Flatten\n",
    "        flattened = pool3.reshape(-1)\n",
    "        \n",
    "        # FC1 + ReLU + Dropout\n",
    "        fc1 = np.dot(flattened, self.fc1_weights) + self.fc1_bias\n",
    "        fc1 = relu(fc1)\n",
    "        \n",
    "        if use_dropout:\n",
    "            dropout_mask = (np.random.rand(*fc1.shape) > dropout_rate).astype(float)\n",
    "            fc1 = fc1 * dropout_mask / (1 - dropout_rate)\n",
    "        \n",
    "        # FC2 (output)\n",
    "        output = np.dot(fc1, self.fc2_weights) + self.fc2_bias\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Create model\n",
    "alexnet = AlexNetSimplified(num_classes=10)\n",
    "print(\"AlexNet (simplified) created\")\n",
    "\n",
    "# Test forward pass\n",
    "test_img = np.random.randn(3, 32, 32)\n",
    "output = alexnet.forward(test_img)\n",
    "print(f\"Input: (3, 32, 32)\")\n",
    "print(f\"Output: {output.shape} (class scores)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simple_images(num_samples=100, image_size=32):\n",
    "    \"\"\"\n",
    "    Generate simple synthetic images with different patterns\n",
    "    Classes:\n",
    "    0: Horizontal stripes\n",
    "    1: Vertical stripes\n",
    "    2: Diagonal stripes\n",
    "    3: Checkerboard\n",
    "    4: Circle\n",
    "    5: Square\n",
    "    6: Cross\n",
    "    7: Triangle\n",
    "    8: Random noise\n",
    "    9: Solid color\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        class_label = i % 10\n",
    "        img = np.zeros((3, image_size, image_size))\n",
    "        \n",
    "        if class_label == 0:  # Horizontal stripes\n",
    "            for row in range(0, image_size, 4):\n",
    "                img[:, row:row+2, :] = 1\n",
    "        \n",
    "        elif class_label == 1:  # Vertical stripes\n",
    "            for col in range(0, image_size, 4):\n",
    "                img[:, :, col:col+2] = 1\n",
    "        \n",
    "        elif class_label == 2:  # Diagonal\n",
    "            for i in range(image_size):\n",
    "                if i < image_size:\n",
    "                    img[:, i, i] = 1\n",
    "                    if i+1 < image_size:\n",
    "                        img[:, i, i+1] = 1\n",
    "        \n",
    "        elif class_label == 3:  # Checkerboard\n",
    "            for i in range(0, image_size, 4):\n",
    "                for j in range(0, image_size, 4):\n",
    "                    if (i//4 + j//4) % 2 == 0:\n",
    "                        img[:, i:i+4, j:j+4] = 1\n",
    "        \n",
    "        elif class_label == 4:  # Circle\n",
    "            center = image_size // 2\n",
    "            radius = image_size // 3\n",
    "            y_grid, x_grid = np.ogrid[:image_size, :image_size]\n",
    "            mask = (x_grid - center)**2 + (y_grid - center)**2 <= radius**2\n",
    "            img[:, mask] = 1\n",
    "        \n",
    "        elif class_label == 5:  # Square\n",
    "            margin = image_size // 4\n",
    "            img[:, margin:-margin, margin:-margin] = 1\n",
    "        \n",
    "        elif class_label == 6:  # Cross\n",
    "            mid = image_size // 2\n",
    "            thickness = 3\n",
    "            img[:, mid-thickness:mid+thickness, :] = 1\n",
    "            img[:, :, mid-thickness:mid+thickness] = 1\n",
    "        \n",
    "        elif class_label == 7:  # Triangle\n",
    "            for i in range(image_size):\n",
    "                width = int((i / image_size) * image_size / 2)\n",
    "                start = image_size // 2 - width\n",
    "                end = image_size // 2 + width\n",
    "                img[:, i, start:end] = 1\n",
    "        \n",
    "        elif class_label == 8:  # Random noise\n",
    "            img = np.random.rand(3, image_size, image_size)\n",
    "        \n",
    "        else:  # Solid\n",
    "            img[:] = 0.7\n",
    "        \n",
    "        # Add color variation\n",
    "        color = np.random.rand(3, 1, 1)\n",
    "        img = img * color\n",
    "        \n",
    "        # Add noise\n",
    "        img += np.random.randn(3, image_size, image_size) * 0.1\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        X.append(img)\n",
    "        y.append(class_label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Generate dataset\n",
    "X_train, y_train = generate_simple_images(200)\n",
    "X_test, y_test = generate_simple_images(50)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Visualize samples\n",
    "class_names = ['H-Stripes', 'V-Stripes', 'Diagonal', 'Checker', 'Circle', \n",
    "               'Square', 'Cross', 'Triangle', 'Noise', 'Solid']\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    # Find first occurrence of each class\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    img = X_train[idx].transpose(1, 2, 0)  # CHW -> HWC\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(class_names[i])\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Synthetic Image Dataset (10 Classes)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "AlexNet used data augmentation extensively - a key innovation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(img):\n",
    "    \"\"\"Horizontal flip\"\"\"\n",
    "    if np.random.rand() > 0.5:\n",
    "        return img[:, :, ::-1].copy()\n",
    "    return img\n",
    "\n",
    "def random_crop(img, crop_size=28):\n",
    "    \"\"\"Random crop\"\"\"\n",
    "    _, h, w = img.shape\n",
    "    top = np.random.randint(0, h - crop_size + 1)\n",
    "    left = np.random.randint(0, w - crop_size + 1)\n",
    "    \n",
    "    cropped = img[:, top:top+crop_size, left:left+crop_size]\n",
    "    \n",
    "    # Resize back to original\n",
    "    # Simple nearest neighbor (for demo)\n",
    "    scale_h = h / crop_size\n",
    "    scale_w = w / crop_size\n",
    "    \n",
    "    resized = np.zeros_like(img)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            src_i = min(int(i / scale_h), crop_size - 1)\n",
    "            src_j = min(int(j / scale_w), crop_size - 1)\n",
    "            resized[:, i, j] = cropped[:, src_i, src_j]\n",
    "    \n",
    "    return resized\n",
    "\n",
    "def add_noise(img, noise_level=0.05):\n",
    "    \"\"\"Add Gaussian noise\"\"\"\n",
    "    noise = np.random.randn(*img.shape) * noise_level\n",
    "    return np.clip(img + noise, 0, 1)\n",
    "\n",
    "def augment_image(img):\n",
    "    \"\"\"Apply random augmentations\"\"\"\n",
    "    img = random_flip(img)\n",
    "    img = random_crop(img)\n",
    "    img = add_noise(img)\n",
    "    return img\n",
    "\n",
    "# Demonstrate augmentation\n",
    "original = X_train[0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "axes[0, 0].imshow(original.transpose(1, 2, 0))\n",
    "axes[0, 0].set_title('Original')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "for i in range(1, 8):\n",
    "    augmented = augment_image(original.copy())\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axes[row, col].imshow(augmented.transpose(1, 2, 0))\n",
    "    axes[row, col].set_title(f'Augmented {i}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learned Filters\n",
    "\n",
    "One of the insights from AlexNet: visualize what the network learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first layer filters\n",
    "filters = alexnet.conv1_filters  # Shape: (32, 3, 3, 3)\n",
    "\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(min(32, len(axes))):\n",
    "    # Normalize filter for visualization\n",
    "    filt = filters[i].transpose(1, 2, 0)  # CHW -> HWC\n",
    "    filt = (filt - filt.min()) / (filt.max() - filt.min() + 1e-8)\n",
    "    \n",
    "    axes[i].imshow(filt)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'F{i}', fontsize=8)\n",
    "\n",
    "plt.suptitle('Conv1 Filters (32 filters, 3x3, RGB)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"These filters learn to detect edges, colors, and simple patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process an image and visualize feature maps\n",
    "test_image = X_train[4]  # Circle\n",
    "\n",
    "# Forward through first conv layer\n",
    "conv1_output = conv2d(test_image, alexnet.conv1_filters, stride=1, padding=1)\n",
    "conv1_output += alexnet.conv1_bias[:, np.newaxis, np.newaxis]\n",
    "conv1_output = relu(conv1_output)\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Original image\n",
    "ax = plt.subplot(6, 6, 1)\n",
    "ax.imshow(test_image.transpose(1, 2, 0))\n",
    "ax.set_title('Input Image', fontsize=10)\n",
    "ax.axis('off')\n",
    "\n",
    "# Feature maps\n",
    "for i in range(min(32, 35)):\n",
    "    ax = plt.subplot(6, 6, i+2)\n",
    "    ax.imshow(conv1_output[i], cmap='viridis')\n",
    "    ax.set_title(f'Map {i}', fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Feature Maps after Conv1 + ReLU', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Different feature maps respond to different patterns in the image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "# Test on a few images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    idx = i * 5  # Sample every 5th image\n",
    "    img = X_test[idx]\n",
    "    true_label = y_test[idx]\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = alexnet.forward(img, use_dropout=False)\n",
    "    probs = softmax(logits)\n",
    "    pred_label = np.argmax(probs)\n",
    "    \n",
    "    # Display\n",
    "    axes[i].imshow(img.transpose(1, 2, 0))\n",
    "    axes[i].set_title(f'True: {class_names[true_label]}\\nPred: {class_names[pred_label]}\\nConf: {probs[pred_label]:.2f}',\n",
    "                     fontsize=9)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('AlexNet Predictions (Untrained)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Model is untrained, so predictions are random!\")\n",
    "print(\"Training would require gradient descent, which we've simplified for clarity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### AlexNet Innovations (2012):\n",
    "\n",
    "1. **ReLU Activation**: Much faster than sigmoid/tanh\n",
    "   - No saturation for positive values\n",
    "   - Faster training (6x compared to tanh)\n",
    "\n",
    "2. **Dropout**: Powerful regularization\n",
    "   - Prevents overfitting\n",
    "   - Used in FC layers (0.5 rate)\n",
    "\n",
    "3. **Data Augmentation**: \n",
    "   - Random crops and flips\n",
    "   - Color jittering\n",
    "   - Artificially increases dataset size\n",
    "\n",
    "4. **GPU Training**: \n",
    "   - Used 2 GTX 580 GPUs\n",
    "   - Enabled training of deep networks\n",
    "\n",
    "5. **Local Response Normalization (LRN)**:\n",
    "   - Lateral inhibition between feature maps\n",
    "   - Less common now (Batch Norm replaced it)\n",
    "\n",
    "### Architecture:\n",
    "```\n",
    "Input (227x227x3)\n",
    "  ↓\n",
    "Conv1 (96 filters, 11x11, stride 4) + ReLU + MaxPool\n",
    "  ↓\n",
    "Conv2 (256 filters, 5x5) + ReLU + MaxPool\n",
    "  ↓\n",
    "Conv3 (384 filters, 3x3) + ReLU\n",
    "  ↓\n",
    "Conv4 (384 filters, 3x3) + ReLU\n",
    "  ↓\n",
    "Conv5 (256 filters, 3x3) + ReLU + MaxPool\n",
    "  ↓\n",
    "FC6 (4096) + ReLU + Dropout\n",
    "  ↓\n",
    "FC7 (4096) + ReLU + Dropout\n",
    "  ↓\n",
    "FC8 (1000 classes) + Softmax\n",
    "```\n",
    "\n",
    "### Impact:\n",
    "- **Won ImageNet 2012**: 15.3% top-5 error (vs 26.2% second place)\n",
    "- **Reignited deep learning**: Showed depth + data + compute works\n",
    "- **GPU revolution**: Made GPUs essential for deep learning\n",
    "- **Inspired modern CNNs**: VGG, ResNet, etc. built on these ideas\n",
    "\n",
    "### Why It Worked:\n",
    "1. Deep architecture (8 layers was deep in 2012!)\n",
    "2. Large dataset (1.2M ImageNet images)\n",
    "3. GPU acceleration (made training feasible)\n",
    "4. Smart regularization (dropout + data aug)\n",
    "5. ReLU activation (faster training)\n",
    "\n",
    "### Modern Perspective:\n",
    "- AlexNet is considered \"simple\" now\n",
    "- ResNets have 100+ layers\n",
    "- Batch Norm replaced LRN\n",
    "- But the core ideas remain:\n",
    "  - Deep hierarchical features\n",
    "  - Convolution for spatial structure\n",
    "  - Data augmentation\n",
    "  - Regularization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
